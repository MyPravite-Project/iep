ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

= IEP-4: Kubernetes for hosting project applications

:toc:
:hide-uri-scheme:
:sect-anchors:

.Metadata
[cols="2"]
|===
| IEP
| 4

| Title
| Kubernetes for hosting project applications

| Author
| link:https://github.com/rtyler[R. Tyler Croy], link:https://github.com/olblak[Olivier Vernin]

| Status
| :speech_balloon: In-process

| Type
| Architecture

| Created
| 2016-12-15
|===


== Abstract

The Jenkins project hosts a number of applications, using different technology
stacks, with
link:https://en.wikipedia.org/wiki/Docker_%28software%29[Docker]
containers as the packaging and runtime environment. While the merits of using Docker
containers to run these applications is not the subject of this IEP document,
the hosting and deployment of these containers is. In essence, some tooling for
safely hosting, deploying, and monitoring containers within the Jenkins
infrastructure is necessary in order to support the applications the project
requires.

== Specification

To support aforementioned containerized applications,
link:http://kubernetes.io[Kubernetes]
(also referred to as "k8s") will be deployed using the
link:https://azure.microsoft.com/en-us/services/container-service/[Azure Container Service]
(ACS).  This specification will detail the *initial* Kubernetes cluster
architecture but is not prescriptive on how the cluster should grow/shrink as
requirements change for the applications hosted.

This specification only outlines the architecture for the "Public Production"
footnoteref:[iep2,https://github.com/jenkins-infra/iep/tree/master/iep-002]
Kubernetes cluster. It is expected that the project will run multiple
Kubernetes clusters, following this architecture, depending on the access
control requirements for each discrete Kubernetes.

At a high level Kubernetes is a master/agent architecture which would live in a
*single region*. For the purposes of Jenkins infrastructure, the production
Kuberenetes clusters would be located in the "East US" Azure region.
footnoteref:[regions,https://azure.microsoft.com/en-us/regions/]

The virtual machines are all
link:https://azure.microsoft.com/en-us/pricing/details/virtual-machines/series/#d-series[D-series]
instances in order to provide an ideal balance of cost and performance. For
more, see <<Costs>> below.


*Kubernetes master*

A cluster would run a single D3v2 instance as the master node


*Kubernetes agents*

A cluster would run agents using a
link:https://azure.microsoft.com/en-us/services/virtual-machine-scale-sets/[Scale Set]
of D2v2 instances, with a minimum of three agents running at all times.



[NOTE]
====
Following
link:https://github.com/jenkins-infra/iep/tree/master/iep-003[IEP-3]
the <<reference-implementation>> uses Terraform to describe the infrastructure
necessary to support this specification.
====


=== Monitoring

As the Jenkins project already uses
link:http://datadoghq.com[Datadog]
for monitoring our production infrastructure, the Kubernetes cluster must
integrate appropriately.

This will be accomplished using the
link:http://docs.datadoghq.com/integrations/kubernetes/[Datadog/Kubernetes integration]
maintained by Datadog themselves.

The integration is will provide metrics for both:

* Kubernetes cluster health/status
* Container health/status running atop the cluster

The metrics required are not specified here under the assumption that all
metrics appropriate for ensuring stable service levels of project
infrastructure will be collected.

=== Logging


Centralized logging for applications hosted within Kubernetes will be provided
a combination of containers in the cluster running
link:https://en.wikipedia.org/wiki/Fluentd[Fluentd]
and the Microsoft
link:http://www.microsoft.com/en-us/cloud-platform/operations-management-suite[Operations Management Suite]
(OMS).

Fluentd container will handle logs based on rules defined by log's type.

As a first iteration, we identify two log's type, archive and stream.
They are explain more in depth below.


==== Type
===== Stream
'Stream' means that their access are almost realtime and 
we only want to retrieve them for a short time period.

Reasons why we consider logs a 'stream log' are:

* Costs, we don't want to pay for useless logs' storage 
* Debugging, we may have to analyze application's behaviour

'Stream' logs will be stored on azure log analytics for 7 days and then trashed.

In order to retrieve logs informations, we'll need access to log analytics dashboard.

*! This is the default behaviour followed by all log's types*

===== Archive
'Archive' means that we want to access them for a long time period.

Reasons why we may consider logs as 'archive' are:

* Need long time period access 
* Want to backup important informations

'Archive' logs will be stored on Azure containers for an undetermined period.
In order to retrieved them, we'll have to request compressed archives from an admin.

N.B We prefer to use Azure container over Azure Shared Disk as we can access logs without having to 
mount azure shared disks.

==== Logging Strategy 
Logs work as follow:

* Docker containers write logs to json files located in /var/log/containers/
* Each kubernetes agent run one fluentd container(daemonset) that read logs from /var/log/containers
and apply 'rules'


.Data flow for k8s logs
[source]
....
+--------------------------------------------------------------+                                                                                                
| K8s Agent:                                                   |
|                                            +------------+    |
|                                            |Container_A |    |
|                                            |            |    |
| K8s agent FS:                              +---------+--+    |
| +--------------------+      <send_logs_to            |       |
| |/var/log/containers |<------------------------------+       |
| +----------+---------+                               |       |
|            |                               +---------+--+    |
|            |                               |Container_B |    |
| Fetch_logs |                               |            |    |
|            v                               +------------+    |         +--------------------+
|      +----------+    apply_rule_stream_logs_to  ---------------------->| Azure LogAnalytics |
|      |Fluentd   +------------------------------/             |         +--------------------+
|      |Container +------------------------------\             |         +--------------------+
|      +----------+   apply_rule_archive_logs_to  ---------------------->| Azure Blob Storage |
|                                                              |         +--------------------+
+--------------------------------------------------------------+
....


In order to know howto apply rules, we can follow 3 strategies.

*We must agree with one of them*

.1) We search for patterns inside logs file.
        
We can use this fluentd plugin  http://docs.fluentd.org/articles/filter_grep[filter_grep] to search for log patterns

ex:
Default apache access log 
....
127.0.0.1 - - [05/Feb/2012:17:11:55 +0000] "GET / HTTP/1.1" 200 140 "-" "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.5 Safari/535.19"
....

Apache access log with type information
....
TO_ARCHIVE_PATTERN 127.0.0.1 - - [05/Feb/2012:17:11:55 +0000] "GET / HTTP/1.1" 200 140 "-" "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/18.0.1025.5 Safari/535.19"
....

Pos: 

* Better granularity as we can define different log type within an application (ERRO,INFO,...)

Cons:

* Error prone, fluentd doesn't know any formats or contents for parsed logs.
* More configurations: we need to modify default logs configuration.
* More work for contributors
* We must rebuild docker image if we want to change log type


.2) We define log's type information based on container's name. 
Container 'fluentd-2ae2r' become 'archive_fluentd-2ae2r' 
Or we can use numbers.
Example 'fluentd-2ae2r' become '0_fluentd-2ae2r' 
where '0' mean by convention 'archive'

pros:

* We don't have to modify default logging configuration.
* Contributors only have to define logs' type in containers' name.
* Easy to handle from fluentd configuration.
* We don't have to rebuild docker image when we change log type.

cons:

* Container names must respect a specific format.
* We must changed container name to change log type

.3) We define logs's type based on container's label.
We define a label 'log_type' with default value set to 'stream'.
If we want to archive logs we can update the value to 'archive'

pros: 

* We don't have to modify default logging configuration.
* We don't have to rebuild docker image when we change log type.
* Contributors only have to define log_type in containers' label.
* Easy to handle from fluentd configuration.

cons:
* ?


A prototype of this architecture can be found in Olivier Vernin's
link:https://github.com/olblak/fluentd-k8s-azure[fluentd-k8s-azure]
repository.


=== Deployment/Orchestration

[NOTE]
====
This section is still a work in progress, awaiting and prototyping by
link:https://github.com/olblak[Olivier Vernin]
====

== Motivation

The motivation for centralizing container hosting is fairly
self-evident. Consistency of management, deployment, logging, monitoring, and
runtime environment will be a major time-saver for volunteers participating in
the Jenkins project.

Additionally, consolidation on a well understood and supported tool
(Kuberenetes) allows the infrastructure team to spend less time operating the
underlying hosting platform.


== Rationale

As mentioned in the <<Abstract>>, the Jenkins project runs containerized
applications, the merits of which are outside the scope of this document.
Thusly this document outlines an approach for managing numerous containers in
Azure.

There is a fundamental assumption being made in using Azure Container Service,
that is: it's cheaper/easier/faster to use a "turn-key" solution for building
and running a container orchestrator (e.g. Kubernetes) than it would be to
build out such a cluster ourselves using virtual machines and Puppet (for
example).

With this assumption, the options provided by ACS are: Kubernetes, Docker
Swarm, or DC/OS.

The selection for Kubernetes largely rests on two criteria:

. Kubernetes is supported in some form by two of the three major cloud vendors
  (Microsoft, Google). Which indicates project maturity and long-term support but
  also flexibility for the Jenkins project to migrate to alternative cloud
  vendors if the need were to arise.
. Developer preference: we prefer Kubernetes and the tooling it provides over the alternatives.

=== Docker Swarm

Docker Swarm is the leading option, behind Kubernetes, But the open source
"swarm mode" functionality is not supported by Azure Container Service, nor is
Docker Swarm supported by any other vendor other than Microsoft at this point.

The focus from Docker, Inc. seems to be more on products such as
link:https://www.docker.com/products/docker-datacenter[Docker Datacenter]
long-term, which makes choosing Docker Swarm on ACS seem risky.

=== DC/OS

Similar to Docker Swarm on ACS, there is no mainstream support for DC/OS on
other cloud providers which suggests either immaturity in the project or lack
of long-term committment by platform vendors to support it.

Additionally, at this point in time, the authors of this document do not know
anybody committed to running production workloads on DC/OS (we're certain they
exist however).

== Costs

[quote, https://azure.microsoft.com/en-us/pricing/details/container-service/]
____
ACS is a free service that clusters Virtual Machines (VMs) into a container
service. You only pay for the VMs and associated storage and networking
resources consumed.
____


Assuming a single minimally scaled cluster with a single master and three
agents, the annual cost of the Kubernetes cluster itself would be: *$3,845.64*.
Obviously as the number of agents increases, the cost will increase per-agent
instance.


.Costs
|===
| Instance | Annual Cost (East US)

| D2v2
| $1278.96

| D3v2
| $2566.68
|===


[[reference-implementation]]
== Reference Implementation


The current reference implementation is authored by
link:https://github.com/olblak[Olivier Vernin]
in
link:https://github.com/jenkins-infra/azure/pull/5[pull request #5]
to the
link:https://github.com/jenkins-infra/azure[azure]
repository.
